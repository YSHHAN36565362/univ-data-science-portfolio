{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "96e53835-3765-45ae-ab3d-16dc434651e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 공통 import\n",
    "import os, json, math, numpy as np, pandas as pd, torch\n",
    "from pathlib import Path\n",
    "from dataclasses import dataclass\n",
    "from typing import Dict, List\n",
    "from sklearn.metrics import f1_score, classification_report, confusion_matrix\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 출력 경로\n",
    "OUT_DIR = Path(\"/data/kobert_outputs_384\")\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# 장치\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device\n",
    "\n",
    "# ====== 경로 ======\n",
    "TRAIN_XLSX = \"D:/학교/대외활동/학술제/train_dataset.xlsx\"\n",
    "VALID_XLSX = \"D:/학교/대외활동/학술제/validation_dataset.xlsx\"\n",
    "\n",
    "# ====== 데이터 로드 ======\n",
    "train = pd.read_excel(TRAIN_XLSX)\n",
    "valid = pd.read_excel(VALID_XLSX)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "65f17399-b8f7-4e25-8180-df89f15263cf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtransformers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m AutoTokenizer, AutoModelForSequenceClassification, get_linear_schedule_with_warmup\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdata\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Dataset, DataLoader\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# ====== 데이터 로드 ======\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\Lib\\site-packages\\transformers\\__init__.py:27\u001b[39m\n\u001b[32m     24\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m TYPE_CHECKING\n\u001b[32m     26\u001b[39m \u001b[38;5;66;03m# Check the dependencies satisfy the minimal versions required.\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m27\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m dependency_versions_check\n\u001b[32m     28\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     29\u001b[39m     OptionalDependencyNotAvailable,\n\u001b[32m     30\u001b[39m     _LazyModule,\n\u001b[32m   (...)\u001b[39m\u001b[32m     36\u001b[39m     is_pretty_midi_available,\n\u001b[32m     37\u001b[39m )\n\u001b[32m     39\u001b[39m \u001b[38;5;66;03m# Note: the following symbols are deliberately exported with `as`\u001b[39;00m\n\u001b[32m     40\u001b[39m \u001b[38;5;66;03m# so that mypy, pylint or other static linters can recognize them,\u001b[39;00m\n\u001b[32m     41\u001b[39m \u001b[38;5;66;03m# given that they are not exported using `__all__` in this file.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\Lib\\site-packages\\transformers\\dependency_versions_check.py:16\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Copyright 2020 The HuggingFace Team. All rights reserved.\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     12\u001b[39m \u001b[38;5;66;03m# See the License for the specific language governing permissions and\u001b[39;00m\n\u001b[32m     13\u001b[39m \u001b[38;5;66;03m# limitations under the License.\u001b[39;00m\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdependency_versions_table\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m deps\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mversions\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m require_version, require_version_core\n\u001b[32m     19\u001b[39m \u001b[38;5;66;03m# define which module versions we always want to check at run time\u001b[39;00m\n\u001b[32m     20\u001b[39m \u001b[38;5;66;03m# (usually the ones defined in `install_requires` in setup.py)\u001b[39;00m\n\u001b[32m     21\u001b[39m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[32m     22\u001b[39m \u001b[38;5;66;03m# order specific notes:\u001b[39;00m\n\u001b[32m     23\u001b[39m \u001b[38;5;66;03m# - tqdm must be checked before tokenizers\u001b[39;00m\n\u001b[32m     25\u001b[39m pkgs_to_check_at_runtime = [\n\u001b[32m     26\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mpython\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     27\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mtqdm\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     37\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mpyyaml\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     38\u001b[39m ]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\Lib\\site-packages\\transformers\\utils\\__init__.py:24\u001b[39m\n\u001b[32m     21\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpackaging\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m version\n\u001b[32m     23\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m __version__\n\u001b[32m---> \u001b[39m\u001b[32m24\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mauto_docstring\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     25\u001b[39m     ClassAttrs,\n\u001b[32m     26\u001b[39m     ClassDocstring,\n\u001b[32m     27\u001b[39m     ImageProcessorArgs,\n\u001b[32m     28\u001b[39m     ModelArgs,\n\u001b[32m     29\u001b[39m     ModelOutputArgs,\n\u001b[32m     30\u001b[39m     auto_class_docstring,\n\u001b[32m     31\u001b[39m     auto_docstring,\n\u001b[32m     32\u001b[39m     get_args_doc_from_source,\n\u001b[32m     33\u001b[39m     parse_docstring,\n\u001b[32m     34\u001b[39m     set_min_indent,\n\u001b[32m     35\u001b[39m )\n\u001b[32m     36\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbackbone_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m BackboneConfigMixin, BackboneMixin\n\u001b[32m     37\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mchat_template_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DocstringParsingException, TypeHintParsingException, get_json_schema\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\Lib\\site-packages\\transformers\\utils\\auto_docstring.py:30\u001b[39m\n\u001b[32m     22\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mregex\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mre\u001b[39;00m\n\u001b[32m     24\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdoc\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     25\u001b[39m     MODELS_TO_PIPELINE,\n\u001b[32m     26\u001b[39m     PIPELINE_TASKS_TO_SAMPLE_DOCSTRINGS,\n\u001b[32m     27\u001b[39m     PT_SAMPLE_DOCSTRINGS,\n\u001b[32m     28\u001b[39m     _prepare_output_docstrings,\n\u001b[32m     29\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m30\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mgeneric\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ModelOutput\n\u001b[32m     33\u001b[39m PATH_TO_TRANSFORMERS = Path(\u001b[33m\"\u001b[39m\u001b[33msrc\u001b[39m\u001b[33m\"\u001b[39m).resolve() / \u001b[33m\"\u001b[39m\u001b[33mtransformers\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     36\u001b[39m AUTODOC_FILES = [\n\u001b[32m     37\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mconfiguration_*.py\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     38\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mmodeling_*.py\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     43\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mfeature_extractor_*.py\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     44\u001b[39m ]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\Lib\\site-packages\\transformers\\utils\\generic.py:51\u001b[39m\n\u001b[32m     47\u001b[39m logger = logging.get_logger(\u001b[34m__name__\u001b[39m)\n\u001b[32m     49\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_torch_available():\n\u001b[32m     50\u001b[39m     \u001b[38;5;66;03m# required for @can_return_tuple decorator to work with torchdynamo\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m51\u001b[39m     \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\n\u001b[32m     53\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodel_debugging_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m model_addition_debugger_context\n\u001b[32m     56\u001b[39m \u001b[38;5;66;03m# vendored from distutils.util\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\Lib\\site-packages\\torch\\__init__.py:281\u001b[39m\n\u001b[32m    277\u001b[39m                     \u001b[38;5;28;01mraise\u001b[39;00m err\n\u001b[32m    279\u001b[39m         kernel32.SetErrorMode(prev_error_mode)\n\u001b[32m--> \u001b[39m\u001b[32m281\u001b[39m     \u001b[43m_load_dll_libraries\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    282\u001b[39m     \u001b[38;5;28;01mdel\u001b[39;00m _load_dll_libraries\n\u001b[32m    285\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_get_cuda_dep_paths\u001b[39m(path: \u001b[38;5;28mstr\u001b[39m, lib_folder: \u001b[38;5;28mstr\u001b[39m, lib_name: \u001b[38;5;28mstr\u001b[39m) -> \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mstr\u001b[39m]:\n\u001b[32m    286\u001b[39m     \u001b[38;5;66;03m# Libraries can either be in\u001b[39;00m\n\u001b[32m    287\u001b[39m     \u001b[38;5;66;03m# path/nvidia/lib_folder/lib or\u001b[39;00m\n\u001b[32m    288\u001b[39m     \u001b[38;5;66;03m# path/nvidia/cuXX/lib (since CUDA 13.0) or\u001b[39;00m\n\u001b[32m    289\u001b[39m     \u001b[38;5;66;03m# path/lib_folder/lib\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\Lib\\site-packages\\torch\\__init__.py:257\u001b[39m, in \u001b[36m_load_dll_libraries\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    255\u001b[39m is_loaded = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    256\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m with_load_library_flags:\n\u001b[32m--> \u001b[39m\u001b[32m257\u001b[39m     res = \u001b[43mkernel32\u001b[49m\u001b[43m.\u001b[49m\u001b[43mLoadLibraryExW\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdll\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0x00001100\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    258\u001b[39m     last_error = ctypes.get_last_error()\n\u001b[32m    259\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m res \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m last_error != \u001b[32m126\u001b[39m:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\IPython\\core\\async_helpers.py:128\u001b[39m, in \u001b[36m_pseudo_sync_runner\u001b[39m\u001b[34m(coro)\u001b[39m\n\u001b[32m    120\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    121\u001b[39m \u001b[33;03mA runner that does not really allow async execution, and just advance the coroutine.\u001b[39;00m\n\u001b[32m    122\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    125\u001b[39m \u001b[33;03mCredit to Nathaniel Smith\u001b[39;00m\n\u001b[32m    126\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    127\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m128\u001b[39m     \u001b[43mcoro\u001b[49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    129\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m    130\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m exc.value\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\IPython\\core\\interactiveshell.py:3413\u001b[39m, in \u001b[36mInteractiveShell.run_cell_async\u001b[39m\u001b[34m(self, raw_cell, store_history, silent, shell_futures, transformed_cell, preprocessing_exc_tuple, cell_id)\u001b[39m\n\u001b[32m   3409\u001b[39m exec_count = \u001b[38;5;28mself\u001b[39m.execution_count\n\u001b[32m   3410\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m result.error_in_exec:\n\u001b[32m   3411\u001b[39m     \u001b[38;5;66;03m# Store formatted traceback and error details\u001b[39;00m\n\u001b[32m   3412\u001b[39m     \u001b[38;5;28mself\u001b[39m.history_manager.exceptions[exec_count] = (\n\u001b[32m-> \u001b[39m\u001b[32m3413\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_format_exception_for_storage\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m.\u001b[49m\u001b[43merror_in_exec\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3414\u001b[39m     )\n\u001b[32m   3416\u001b[39m \u001b[38;5;66;03m# Each cell is a *single* input, regardless of how many lines it has\u001b[39;00m\n\u001b[32m   3417\u001b[39m \u001b[38;5;28mself\u001b[39m.execution_count += \u001b[32m1\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\IPython\\core\\interactiveshell.py:3467\u001b[39m, in \u001b[36mInteractiveShell._format_exception_for_storage\u001b[39m\u001b[34m(self, exception, filename, running_compiled_code)\u001b[39m\n\u001b[32m   3464\u001b[39m         stb = evalue._render_traceback_()\n\u001b[32m   3465\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   3466\u001b[39m         \u001b[38;5;66;03m# Otherwise, use InteractiveTB to format the traceback.\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m3467\u001b[39m         stb = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mInteractiveTB\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstructured_traceback\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3468\u001b[39m \u001b[43m            \u001b[49m\u001b[43metype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtb_offset\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\n\u001b[32m   3469\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3470\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[32m   3471\u001b[39m     \u001b[38;5;66;03m# In case formatting fails, fallback to Python's built-in formatting.\u001b[39;00m\n\u001b[32m   3472\u001b[39m     stb = traceback.format_exception(etype, evalue, tb)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\IPython\\core\\ultratb.py:1185\u001b[39m, in \u001b[36mAutoFormattedTB.structured_traceback\u001b[39m\u001b[34m(self, etype, evalue, etb, tb_offset, context)\u001b[39m\n\u001b[32m   1183\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1184\u001b[39m     \u001b[38;5;28mself\u001b[39m.tb = etb\n\u001b[32m-> \u001b[39m\u001b[32m1185\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mFormattedTB\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstructured_traceback\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1186\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43metype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43metb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtb_offset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\n\u001b[32m   1187\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\IPython\\core\\ultratb.py:1056\u001b[39m, in \u001b[36mFormattedTB.structured_traceback\u001b[39m\u001b[34m(self, etype, evalue, etb, tb_offset, context)\u001b[39m\n\u001b[32m   1053\u001b[39m mode = \u001b[38;5;28mself\u001b[39m.mode\n\u001b[32m   1054\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.verbose_modes:\n\u001b[32m   1055\u001b[39m     \u001b[38;5;66;03m# Verbose modes need a full traceback\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1056\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVerboseTB\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstructured_traceback\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1057\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43metype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43metb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtb_offset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\n\u001b[32m   1058\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1059\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m mode == \u001b[33m\"\u001b[39m\u001b[33mDocs\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m   1060\u001b[39m     \u001b[38;5;66;03m# return DocTB\u001b[39;00m\n\u001b[32m   1061\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m DocTB(\n\u001b[32m   1062\u001b[39m         theme_name=\u001b[38;5;28mself\u001b[39m._theme_name,\n\u001b[32m   1063\u001b[39m         call_pdb=\u001b[38;5;28mself\u001b[39m.call_pdb,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1071\u001b[39m         etype, evalue, etb, tb_offset, \u001b[32m1\u001b[39m\n\u001b[32m   1072\u001b[39m     )  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\IPython\\core\\ultratb.py:864\u001b[39m, in \u001b[36mVerboseTB.structured_traceback\u001b[39m\u001b[34m(self, etype, evalue, etb, tb_offset, context)\u001b[39m\n\u001b[32m    855\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mstructured_traceback\u001b[39m(\n\u001b[32m    856\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    857\u001b[39m     etype: \u001b[38;5;28mtype\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    861\u001b[39m     context: \u001b[38;5;28mint\u001b[39m = \u001b[32m5\u001b[39m,\n\u001b[32m    862\u001b[39m ) -> \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mstr\u001b[39m]:\n\u001b[32m    863\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Return a nice text document describing the traceback.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m864\u001b[39m     formatted_exceptions: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mstr\u001b[39m]] = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mformat_exception_as_a_whole\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    865\u001b[39m \u001b[43m        \u001b[49m\u001b[43metype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43metb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtb_offset\u001b[49m\n\u001b[32m    866\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    868\u001b[39m     termsize = \u001b[38;5;28mmin\u001b[39m(\u001b[32m75\u001b[39m, get_terminal_size()[\u001b[32m0\u001b[39m])\n\u001b[32m    869\u001b[39m     theme = theme_table[\u001b[38;5;28mself\u001b[39m._theme_name]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\IPython\\core\\ultratb.py:776\u001b[39m, in \u001b[36mVerboseTB.format_exception_as_a_whole\u001b[39m\u001b[34m(self, etype, evalue, etb, context, tb_offset)\u001b[39m\n\u001b[32m    766\u001b[39m         frames.append(\n\u001b[32m    767\u001b[39m             theme_table[\u001b[38;5;28mself\u001b[39m._theme_name].format(\n\u001b[32m    768\u001b[39m                 [\n\u001b[32m   (...)\u001b[39m\u001b[32m    773\u001b[39m             )\n\u001b[32m    774\u001b[39m         )\n\u001b[32m    775\u001b[39m         skipped = \u001b[32m0\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m776\u001b[39m     frames.append(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mformat_record\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrecord\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m    777\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m skipped:\n\u001b[32m    778\u001b[39m     frames.append(\n\u001b[32m    779\u001b[39m         theme_table[\u001b[38;5;28mself\u001b[39m._theme_name].format(\n\u001b[32m    780\u001b[39m             [\n\u001b[32m   (...)\u001b[39m\u001b[32m    785\u001b[39m         )\n\u001b[32m    786\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\IPython\\core\\ultratb.py:651\u001b[39m, in \u001b[36mVerboseTB.format_record\u001b[39m\u001b[34m(self, frame_info)\u001b[39m\n\u001b[32m    648\u001b[39m result += \u001b[33m\"\u001b[39m\u001b[33m, \u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m call \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    649\u001b[39m result += \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcall\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    650\u001b[39m result += theme_table[\u001b[38;5;28mself\u001b[39m._theme_name].format(\n\u001b[32m--> \u001b[39m\u001b[32m651\u001b[39m     \u001b[43m_format_traceback_lines\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    652\u001b[39m \u001b[43m        \u001b[49m\u001b[43mframe_info\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlines\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    653\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtheme_table\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_theme_name\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    654\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mhas_colors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    655\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlvals_toks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    656\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    657\u001b[39m )\n\u001b[32m    658\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\IPython\\core\\tbtools.py:99\u001b[39m, in \u001b[36m_format_traceback_lines\u001b[39m\u001b[34m(lines, theme, has_colors, lvals_toks)\u001b[39m\n\u001b[32m     96\u001b[39m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m     98\u001b[39m lineno = stack_line.lineno\n\u001b[32m---> \u001b[39m\u001b[32m99\u001b[39m line = \u001b[43mstack_line\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrender\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpygmented\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhas_colors\u001b[49m\u001b[43m)\u001b[49m.rstrip(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m) + \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    100\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m stack_line.is_current:\n\u001b[32m    101\u001b[39m     \u001b[38;5;66;03m# This is the line with the error\u001b[39;00m\n\u001b[32m    102\u001b[39m     pad = numbers_width - \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mstr\u001b[39m(lineno))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\stack_data\\core.py:391\u001b[39m, in \u001b[36mLine.render\u001b[39m\u001b[34m(self, markers, strip_leading_indent, pygmented, escape_html)\u001b[39m\n\u001b[32m    389\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m pygmented \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.frame_info.scope:\n\u001b[32m    390\u001b[39m     assert_(\u001b[38;5;129;01mnot\u001b[39;00m markers, \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mCannot use pygmented with markers\u001b[39m\u001b[33m\"\u001b[39m))\n\u001b[32m--> \u001b[39m\u001b[32m391\u001b[39m     start_line, lines = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mframe_info\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_pygmented_scope_lines\u001b[49m\n\u001b[32m    392\u001b[39m     result = lines[\u001b[38;5;28mself\u001b[39m.lineno - start_line]\n\u001b[32m    393\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m strip_leading_indent:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\stack_data\\utils.py:145\u001b[39m, in \u001b[36mcached_property.cached_property_wrapper\u001b[39m\u001b[34m(self, obj, _cls)\u001b[39m\n\u001b[32m    142\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m obj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    143\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m145\u001b[39m value = obj.\u001b[34m__dict__\u001b[39m[\u001b[38;5;28mself\u001b[39m.func.\u001b[34m__name__\u001b[39m] = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    146\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m value\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\stack_data\\core.py:824\u001b[39m, in \u001b[36mFrameInfo._pygmented_scope_lines\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    821\u001b[39m     ranges = []\n\u001b[32m    823\u001b[39m code = atext.get_text(scope)\n\u001b[32m--> \u001b[39m\u001b[32m824\u001b[39m lines = \u001b[43m_pygmented_with_ranges\u001b[49m\u001b[43m(\u001b[49m\u001b[43mformatter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mranges\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    826\u001b[39m start_line = \u001b[38;5;28mself\u001b[39m.source.line_range(scope)[\u001b[32m0\u001b[39m]\n\u001b[32m    828\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m start_line, lines\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\stack_data\\utils.py:166\u001b[39m, in \u001b[36m_pygmented_with_ranges\u001b[39m\u001b[34m(formatter, code, ranges)\u001b[39m\n\u001b[32m    164\u001b[39m lexer = MyLexer(stripnl=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m    165\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m166\u001b[39m     highlighted = \u001b[43mpygments\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhighlight\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mformatter\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    167\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[32m    168\u001b[39m     \u001b[38;5;66;03m# When pygments fails, prefer code without highlighting over crashing\u001b[39;00m\n\u001b[32m    169\u001b[39m     highlighted = code\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\pygments\\__init__.py:82\u001b[39m, in \u001b[36mhighlight\u001b[39m\u001b[34m(code, lexer, formatter, outfile)\u001b[39m\n\u001b[32m     77\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mhighlight\u001b[39m(code, lexer, formatter, outfile=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m     78\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     79\u001b[39m \u001b[33;03m    This is the most high-level highlighting function. It combines `lex` and\u001b[39;00m\n\u001b[32m     80\u001b[39m \u001b[33;03m    `format` in one function.\u001b[39;00m\n\u001b[32m     81\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m82\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mlex\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlexer\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mformatter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutfile\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\pygments\\__init__.py:64\u001b[39m, in \u001b[36mformat\u001b[39m\u001b[34m(tokens, formatter, outfile)\u001b[39m\n\u001b[32m     62\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m outfile:\n\u001b[32m     63\u001b[39m     realoutfile = \u001b[38;5;28mgetattr\u001b[39m(formatter, \u001b[33m'\u001b[39m\u001b[33mencoding\u001b[39m\u001b[33m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mand\u001b[39;00m BytesIO() \u001b[38;5;129;01mor\u001b[39;00m StringIO()\n\u001b[32m---> \u001b[39m\u001b[32m64\u001b[39m     \u001b[43mformatter\u001b[49m\u001b[43m.\u001b[49m\u001b[43mformat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtokens\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrealoutfile\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     65\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m realoutfile.getvalue()\n\u001b[32m     66\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\pygments\\formatters\\terminal256.py:250\u001b[39m, in \u001b[36mTerminal256Formatter.format\u001b[39m\u001b[34m(self, tokensource, outfile)\u001b[39m\n\u001b[32m    249\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mformat\u001b[39m(\u001b[38;5;28mself\u001b[39m, tokensource, outfile):\n\u001b[32m--> \u001b[39m\u001b[32m250\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mFormatter\u001b[49m\u001b[43m.\u001b[49m\u001b[43mformat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokensource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutfile\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\pygments\\formatter.py:124\u001b[39m, in \u001b[36mFormatter.format\u001b[39m\u001b[34m(self, tokensource, outfile)\u001b[39m\n\u001b[32m    121\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.encoding:\n\u001b[32m    122\u001b[39m     \u001b[38;5;66;03m# wrap the outfile in a StreamWriter\u001b[39;00m\n\u001b[32m    123\u001b[39m     outfile = codecs.lookup(\u001b[38;5;28mself\u001b[39m.encoding)[\u001b[32m3\u001b[39m](outfile)\n\u001b[32m--> \u001b[39m\u001b[32m124\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mformat_unencoded\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtokensource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutfile\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\pygments\\formatters\\terminal256.py:261\u001b[39m, in \u001b[36mTerminal256Formatter.format_unencoded\u001b[39m\u001b[34m(self, tokensource, outfile)\u001b[39m\n\u001b[32m    258\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m ttype \u001b[38;5;129;01mand\u001b[39;00m not_found:\n\u001b[32m    259\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    260\u001b[39m         \u001b[38;5;66;03m# outfile.write( \"<\" + str(ttype) + \">\" )\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m261\u001b[39m         on, off = \u001b[38;5;28mself\u001b[39m.style_string[\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mttype\u001b[49m\u001b[43m)\u001b[49m]\n\u001b[32m    263\u001b[39m         \u001b[38;5;66;03m# Like TerminalFormatter, add \"reset colors\" escape sequence\u001b[39;00m\n\u001b[32m    264\u001b[39m         \u001b[38;5;66;03m# on newline.\u001b[39;00m\n\u001b[32m    265\u001b[39m         spl = value.split(\u001b[33m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m'\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\pygments\\token.py:44\u001b[39m, in \u001b[36m_TokenType.__repr__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     43\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__repr__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m---> \u001b[39m\u001b[32m44\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[33m'\u001b[39m\u001b[33mToken\u001b[39m\u001b[33m'\u001b[39m + (\u001b[38;5;28mself\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m'\u001b[39m\u001b[33m.\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[33m'\u001b[39m\u001b[33m'\u001b[39m) + \u001b[33;43m'\u001b[39;49m\u001b[33;43m.\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, get_linear_schedule_with_warmup\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# ====== (필요시) 컬럼명 매핑 ======\n",
    "rename = {\n",
    "    \"ID\":\"id\",\"Datastamp\":\"datastamp\",\"title\":\"title\",\"abstract\":\"abstract\",\n",
    "    \"publisher\":\"publisher\",\"issn\":\"issn\",\"creator\":\"creator\",\"label\":\"label\",\n",
    "    \"게재일자\":\"datastamp\",\"제목\":\"title\",\"요약\":\"abstract\",\"학회지\":\"publisher\",\"저자\":\"creator\",\"주제분류\":\"label\",\n",
    "}\n",
    "train = train.rename(columns=rename); valid = valid.rename(columns=rename)\n",
    "\n",
    "# ====== 기본 클린업 & 입력 텍스트 ======\n",
    "for c in [\"title\",\"abstract\",\"publisher\",\"issn\",\"creator\",\"label\"]:\n",
    "    if c in train: train[c] = train[c].astype(str).replace({\"nan\":\"\"}).str.strip()\n",
    "    if c in valid: valid[c] = valid[c].astype(str).replace({\"nan\":\"\"}).str.strip()\n",
    "\n",
    "train[\"text\"] = (train.get(\"title\",\"\") + \" [SEP] \" + train.get(\"abstract\",\"\")).str.strip()\n",
    "valid[\"text\"] = (valid.get(\"title\",\"\") + \" [SEP] \" + valid.get(\"abstract\",\"\")).str.strip()\n",
    "\n",
    "# ====== 라벨 인코딩(Train 기준) ======\n",
    "labels: List[str] = sorted(train[\"label\"].dropna().unique().tolist())\n",
    "lab2id: Dict[str,int] = {l:i for i,l in enumerate(labels)}\n",
    "id2lab: Dict[int,str] = {i:l for l,i in lab2id.items()}\n",
    "\n",
    "train[\"y\"] = train[\"label\"].map(lab2id)\n",
    "valid[\"y\"] = valid[\"label\"].map(lab2id)\n",
    "\n",
    "# 저장(서빙/복원용)\n",
    "(OUT_DIR/\"label2id.json\").write_text(json.dumps(lab2id, ensure_ascii=False, indent=2), encoding=\"utf-8\")\n",
    "\n",
    "# ====== 하이퍼파라미터 ======\n",
    "MODEL_NAME = \"skt/kobert-base-v1\"  # HF KoBERT\n",
    "MAX_LEN    = 384\n",
    "BATCH      = 32\n",
    "EPOCHS     = 50\n",
    "LR         = 2e-5\n",
    "PATIENCE   = 8  # F1 early stopping\n",
    "\n",
    "# ====== 데이터셋 ======\n",
    "class PaperDS(Dataset):\n",
    "    def __init__(self, df: pd.DataFrame, tok, max_len: int):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.tok = tok\n",
    "        self.max_len = max_len\n",
    "    def __len__(self): return len(self.df)\n",
    "    def __getitem__(self, i: int):\n",
    "        text = self.df.loc[i, \"text\"]\n",
    "        y    = int(self.df.loc[i, \"y\"])\n",
    "        enc = self.tok(text, truncation=True, padding=\"max_length\", max_length=self.max_len)\n",
    "        item = {k: torch.tensor(v) for k,v in enc.items()}\n",
    "        item[\"labels\"] = torch.tensor(y)\n",
    "        return item\n",
    "\n",
    "# ====== 토크나이저/모델 ======\n",
    "tok = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME, num_labels=len(lab2id)).to(device)\n",
    "\n",
    "# ====== DataLoader ======\n",
    "train_ds = PaperDS(train, tok, MAX_LEN)\n",
    "valid_ds = PaperDS(valid, tok, MAX_LEN)\n",
    "train_dl = DataLoader(train_ds, batch_size=BATCH, shuffle=True)\n",
    "valid_dl = DataLoader(valid_ds, batch_size=BATCH, shuffle=False)\n",
    "\n",
    "# ====== 불균형 보정: class_weight ======\n",
    "cw = compute_class_weight(class_weight=\"balanced\", classes=np.arange(len(lab2id)), y=train[\"y\"].values)\n",
    "cw = torch.tensor(cw, dtype=torch.float32, device=device)\n",
    "criterion = torch.nn.CrossEntropyLoss(weight=cw)\n",
    "\n",
    "# ====== 옵티마이저/스케줄러 ======\n",
    "optim = torch.optim.AdamW(model.parameters(), lr=LR)\n",
    "total_steps = EPOCHS * len(train_dl)\n",
    "sched = get_linear_schedule_with_warmup(optim, int(0.1*total_steps), total_steps)\n",
    "\n",
    "# ====== 학습루프 ======\n",
    "best_f1, wait = 0.0, 0\n",
    "def evaluate(model):\n",
    "    model.eval(); preds=[]; trues=[]\n",
    "    with torch.no_grad():\n",
    "        for batch in valid_dl:\n",
    "            batch = {k:v.to(device) for k,v in batch.items()}\n",
    "            logits = model(input_ids=batch[\"input_ids\"], attention_mask=batch[\"attention_mask\"]).logits\n",
    "            preds.extend(torch.argmax(logits, dim=-1).cpu().tolist())\n",
    "            trues.extend(batch[\"labels\"].cpu().tolist())\n",
    "    macro_f1 = f1_score(trues, preds, average=\"macro\")\n",
    "    rep = classification_report(trues, preds, target_names=[id2lab[i] for i in range(len(id2lab))], digits=4)\n",
    "    return macro_f1, rep, preds, trues\n",
    "\n",
    "for epoch in range(1, EPOCHS+1):\n",
    "    model.train()\n",
    "    for batch in train_dl:\n",
    "        batch = {k:v.to(device) for k,v in batch.items()}\n",
    "        logits = model(input_ids=batch[\"input_ids\"], attention_mask=batch[\"attention_mask\"]).logits\n",
    "        loss = criterion(logits, batch[\"labels\"])\n",
    "        optim.zero_grad(); loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        optim.step(); sched.step()\n",
    "\n",
    "    f1, rep, pv, yv = evaluate(model)\n",
    "    print(f\"[384] Epoch {epoch} | Val Macro-F1: {f1:.4f}\")\n",
    "    # 예측 저장(에폭별)\n",
    "    pd.DataFrame({\n",
    "        \"id\": valid[\"id\"] if \"id\" in valid.columns else range(len(valid)),\n",
    "        \"gold\": [id2lab[i] for i in yv],\n",
    "        \"pred\": [id2lab[i] for i in pv],\n",
    "    }).to_csv(OUT_DIR / f\"preds_epoch{epoch}.csv\", index=False, encoding=\"utf-8\")\n",
    "\n",
    "    if f1 > best_f1:\n",
    "        best_f1, wait = f1, 0\n",
    "        model.save_pretrained(OUT_DIR/\"best_model\")\n",
    "        tok.save_pretrained(OUT_DIR/\"best_model\")\n",
    "    else:\n",
    "        wait += 1\n",
    "        if wait > PATIENCE:\n",
    "            break\n",
    "\n",
    "print(\"[384] Best Val Macro-F1:\", round(best_f1, 4))\n",
    "\n",
    "# ====== 최종 리포트/혼동행렬 저장 ======\n",
    "# 가장 마지막 에폭 파일 사용\n",
    "pred_files = sorted([p for p in OUT_DIR.glob(\"preds_epoch*.csv\")])\n",
    "pred_df = pd.read_csv(pred_files[-1])\n",
    "labels_sorted = sorted(list(set(pred_df[\"gold\"].unique()) | set(pred_df[\"pred\"].unique())))\n",
    "lab2tmp = {l:i for i,l in enumerate(labels_sorted)}\n",
    "cm = confusion_matrix(pred_df[\"gold\"].map(lab2tmp), pred_df[\"pred\"].map(lab2tmp), labels=list(range(len(labels_sorted))))\n",
    "\n",
    "# 혼동행렬 그리기(간단 버전)\n",
    "plt.figure(figsize=(7,6))\n",
    "plt.imshow(cm, aspect='auto')\n",
    "plt.xticks(range(len(labels_sorted)), labels_sorted, rotation=45, ha='right')\n",
    "plt.yticks(range(len(labels_sorted)), labels_sorted)\n",
    "plt.xlabel(\"Predicted\"); plt.ylabel(\"True\"); plt.title(\"KoBERT Confusion Matrix (384)\")\n",
    "plt.colorbar()\n",
    "plt.tight_layout()\n",
    "plt.savefig(OUT_DIR/\"confusion_matrix.png\", dpi=220)\n",
    "plt.show()\n",
    "\n",
    "# 라벨별 상세 리포트 저장\n",
    "from sklearn.metrics import classification_report\n",
    "rep_json = classification_report(\n",
    "    pred_df[\"gold\"].map(lab2tmp),\n",
    "    pred_df[\"pred\"].map(lab2tmp),\n",
    "    target_names=labels_sorted,\n",
    "    output_dict=True,\n",
    "    digits=4\n",
    ")\n",
    "pd.DataFrame(rep_json).transpose().to_csv(OUT_DIR/\"label_report.csv\", encoding=\"utf-8\")\n",
    "print(\"Saved to:\", str(OUT_DIR))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51fc5dee-ae20-4b99-a6c5-488dd7cf6bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 선택 (정확도 향상)\n",
    "from torch.nn import functional as F\n",
    "\n",
    "OUT_DIR_512 = Path(\"/mnt/data/kobert_outputs_512\"); OUT_DIR_512.mkdir(parents=True, exist_ok=True)\n",
    "MAX_LEN_512, BATCH_512 = 512, 8\n",
    "\n",
    "# 512 데이터로더\n",
    "tok2 = tok  # 같은 토크나이저 사용\n",
    "class PaperDS512(PaperDS):\n",
    "    pass\n",
    "train_dl2 = DataLoader(PaperDS512(train, tok2, MAX_LEN_512), batch_size=BATCH_512, shuffle=True)\n",
    "valid_dl2 = DataLoader(PaperDS512(valid, tok2, MAX_LEN_512), batch_size=BATCH_512, shuffle=False)\n",
    "\n",
    "# 512 모델/학습\n",
    "model2 = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME, num_labels=len(lab2id)).to(device)\n",
    "criterion2 = torch.nn.CrossEntropyLoss(weight=cw)\n",
    "optim2 = torch.optim.AdamW(model2.parameters(), lr=LR)\n",
    "total_steps2 = EPOCHS * len(train_dl2)\n",
    "sched2 = get_linear_schedule_with_warmup(optim2, int(0.1*total_steps2), total_steps2)\n",
    "\n",
    "best_f1_512, wait = 0.0, 0\n",
    "for epoch in range(1, EPOCHS+1):\n",
    "    model2.train()\n",
    "    for batch in train_dl2:\n",
    "        batch = {k:v.to(device) for k,v in batch.items()}\n",
    "        logits = model2(input_ids=batch[\"input_ids\"], attention_mask=batch[\"attention_mask\"]).logits\n",
    "        loss = criterion2(logits, batch[\"labels\"])\n",
    "        optim2.zero_grad(); loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model2.parameters(), 1.0)\n",
    "        optim2.step(); sched2.step()\n",
    "\n",
    "    # 평가\n",
    "    model2.eval(); preds=[]; trues=[]\n",
    "    with torch.no_grad():\n",
    "        for batch in valid_dl2:\n",
    "            batch = {k:v.to(device) for k,v in batch.items()}\n",
    "            logits = model2(input_ids=batch[\"input_ids\"], attention_mask=batch[\"attention_mask\"]).logits\n",
    "            preds.extend(torch.argmax(logits, dim=-1).cpu().tolist())\n",
    "            trues.extend(batch[\"labels\"].cpu().tolist())\n",
    "    f1 = f1_score(trues, preds, average=\"macro\")\n",
    "    print(f\"[512] Epoch {epoch} | Val Macro-F1: {f1:.4f}\")\n",
    "\n",
    "    pd.DataFrame({\n",
    "        \"id\": valid[\"id\"] if \"id\" in valid.columns else range(len(valid)),\n",
    "        \"gold\": [id2lab[i] for i in trues],\n",
    "        \"pred\": [id2lab[i] for i in preds],\n",
    "    }).to_csv(OUT_DIR_512 / f\"preds_epoch{epoch}.csv\", index=False, encoding=\"utf-8\")\n",
    "\n",
    "    if f1 > best_f1_512:\n",
    "        best_f1_512, wait = f1, 0\n",
    "        model2.save_pretrained(OUT_DIR_512/\"best_model\")\n",
    "        tok2.save_pretrained(OUT_DIR_512/\"best_model\")\n",
    "    else:\n",
    "        wait += 1\n",
    "        if wait > PATIENCE:\n",
    "            break\n",
    "\n",
    "print(\"[512] Best Val Macro-F1:\", round(best_f1_512, 4))\n",
    "\n",
    "# ====== soft-vote 앙상블 (384/512) ======\n",
    "def probs_from(model_dir, df, max_len, bs=32):\n",
    "    tokA = AutoTokenizer.from_pretrained(model_dir)\n",
    "    dsA = PaperDS(df, tokA, max_len)\n",
    "    dlA = DataLoader(dsA, batch_size=bs, shuffle=False)\n",
    "    mdlA = AutoModelForSequenceClassification.from_pretrained(model_dir).to(device).eval()\n",
    "    probs=[]; ys=[]\n",
    "    with torch.no_grad():\n",
    "        for batch in dlA:\n",
    "            b = {k:v.to(device) for k,v in batch.items()}\n",
    "            logits = mdlA(input_ids=b[\"input_ids\"], attention_mask=b[\"attention_mask\"]).logits\n",
    "            probs.append(F.softmax(logits, dim=-1).cpu().numpy())\n",
    "            ys.extend(b[\"labels\"].cpu().tolist())\n",
    "    return np.vstack(probs), np.array(ys)\n",
    "\n",
    "p384, yv = probs_from(str(OUT_DIR/\"best_model\"), valid, 384, bs=32)\n",
    "p512, _  = probs_from(str(OUT_DIR_512/\"best_model\"), valid, 512, bs=32)\n",
    "\n",
    "p_ens = (p384 + p512) / 2.0\n",
    "pred_ens = p_ens.argmax(axis=1)\n",
    "\n",
    "print(\"Ensemble Macro-F1:\", f1_score(yv, pred_ens, average=\"macro\"))\n",
    "print(classification_report(yv, pred_ens, target_names=[id2lab[i] for i in range(len(id2lab))]))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
